{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Implementation\n",
    "\n",
    "Date: 2018-01-23\n",
    "\n",
    "Reference: https://github.com/nlintz/TensorFlow-Tutorials/blob/master/08_word2vec.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "embedding_size=2\n",
    "num_negativeSample=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: Sample Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the sentence is 12\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"the quick brown fox jumped over the lazy dog\",\n",
    "            \"I love cats and dogs\",\n",
    "            \"we all love cats and dogs\",\n",
    "            \"cats and dogs are great\",\n",
    "            \"sung likes cats\",\n",
    "            \"she loves dogs\",\n",
    "            \"cats can be very independent\",\n",
    "            \"cats are great companions when they want to be\",\n",
    "            \"cats are playful\",\n",
    "            \"cats are natural hunters\",\n",
    "            \"It's raining cats and dogs\",\n",
    "            \"dogs and cats love sung\"]\n",
    "print(\"The length of the sentence is\", len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence to Words (Just cut!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of words is 62\n",
      "\n",
      "\n",
      "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog', 'I', 'love', 'cats', 'and', 'dogs', 'we', 'all', 'love', 'cats', 'and', 'dogs', 'cats', 'and', 'dogs', 'are', 'great', 'sung', 'likes', 'cats', 'she', 'loves', 'dogs', 'cats', 'can', 'be', 'very', 'independent', 'cats', 'are', 'great', 'companions', 'when', 'they', 'want', 'to', 'be', 'cats', 'are', 'playful', 'cats', 'are', 'natural', 'hunters', \"It's\", 'raining', 'cats', 'and', 'dogs', 'dogs', 'and', 'cats', 'love', 'sung']\n"
     ]
    }
   ],
   "source": [
    "words=\" \".join(sentences).split() # setnence를 Words단위로 split한다.\n",
    "print(\"The length of words is\", len(words))\n",
    "print(\"\\n\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence to Counts\n",
    "\n",
    "How many words appear in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 리스트 내의 요소가 몇번이나 반복되었는지 카운트를 해준다.\n",
    "# Counter().most_common(n):= 상위 n개를 return 해준다. \n",
    "# () 공백으로 비웠을 경우, 모든 element를 return 한다.\n",
    "count = collections.Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cats', 10), ('dogs', 6), ('and', 5), ('are', 4), ('love', 3), ('the', 2), ('great', 2), ('sung', 2), ('be', 2), ('quick', 1), ('brown', 1), ('fox', 1), ('jumped', 1), ('over', 1), ('lazy', 1), ('dog', 1), ('I', 1), ('we', 1), ('all', 1), ('likes', 1), ('she', 1), ('loves', 1), ('can', 1), ('very', 1), ('independent', 1), ('companions', 1), ('when', 1), ('they', 1), ('want', 1), ('to', 1), ('playful', 1), ('natural', 1), ('hunters', 1), (\"It's\", 1), ('raining', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(count) # count가 실제로 어떻게 구성되었는지 보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words vs. Count\n",
    "\n",
    "Words List와 Count List가 어떻게 구성되었는지 비교해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the']\n",
      "count: [('cats', 10), ('dogs', 6), ('and', 5), ('are', 4), ('love', 3), ('the', 2), ('great', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(\"words:\", words[0:7]) # 받은 dataset 내의 단어 순서대로 ordering 되어 있다.\n",
    "print(\"count:\", count[0:7]) # most_common(출현 빈도수) 기준으로 ordering 되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dictionaries\n",
    "\n",
    "이제 슬슬 word vector를 만들어야 하기 때문에 단어에 인덱싱을 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of vocabulary is  35\n"
     ]
    }
   ],
   "source": [
    "rdic=[idx[0] for idx in count] # count list에 있는 {cats,10}, {dogs, 6} 이런것에서 단어들만 뽑아낸다.\n",
    "dic={w: idx for idx, w in enumerate(rdic)} # rdic에서 뽑아낸 단어들을 순서대로 0, 1, ...,(n-1) 인덱싱 한다.\n",
    "vocab_size=len(dic) # 우리가 얻은 dataset에 있는 총 단어의 갯수\n",
    "print(\"The total size of vocabulary is \", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 만든 rdic과 dic의 구성도 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdic:  ['cats', 'dogs', 'and', 'are', 'love', 'the', 'great', 'sung', 'be', 'quick', 'brown', 'fox', 'jumped', 'over', 'lazy', 'dog', 'I', 'we', 'all', 'likes', 'she', 'loves', 'can', 'very', 'independent', 'companions', 'when', 'they', 'want', 'to', 'playful', 'natural', 'hunters', \"It's\", 'raining']\n",
      "\n",
      "\n",
      "dic:  {'cats': 0, 'dogs': 1, 'and': 2, 'are': 3, 'love': 4, 'the': 5, 'great': 6, 'sung': 7, 'be': 8, 'quick': 9, 'brown': 10, 'fox': 11, 'jumped': 12, 'over': 13, 'lazy': 14, 'dog': 15, 'I': 16, 'we': 17, 'all': 18, 'likes': 19, 'she': 20, 'loves': 21, 'can': 22, 'very': 23, 'independent': 24, 'companions': 25, 'when': 26, 'they': 27, 'want': 28, 'to': 29, 'playful': 30, 'natural': 31, 'hunters': 32, \"It's\": 33, 'raining': 34}\n"
     ]
    }
   ],
   "source": [
    "print(\"rdic: \", rdic)\n",
    "print(\"\\n\")\n",
    "print(\"dic: \", dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약, dictionary에서 dog의 인덱싱번호를 알고싶다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(dic['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(rdic[15]) # 확인되었다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Indexed word data (ordered)\n",
    "\n",
    "우리가 받은 dataset(word로 구분된)에 아까 인덱싱한 번호를 부여해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 9, 10, 11, 12, 13, 5, 14, 15, 16, 4, 0, 2, 1, 17, 18, 4, 0, 2, 1, 0, 2, 1, 3, 6, 7, 19, 0, 20, 21, 1, 0, 22, 8, 23, 24, 0, 3, 6, 25, 26, 27, 28, 29, 8, 0, 3, 30, 0, 3, 31, 32, 33, 34, 0, 2, 1, 1, 2, 0, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "data=[dic[i] for i in words]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Cbow_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5, 10], 9], [[9, 11], 10], [[10, 12], 11], [[11, 13], 12], [[12, 5], 13], [[13, 14], 5], [[5, 15], 14], [[14, 16], 15], [[15, 4], 16], [[16, 0], 4]]\n"
     ]
    }
   ],
   "source": [
    "cbow_pairs=[]\n",
    "# cbow 에서의 input은 현재 i번째 단어 기준으로 양쪽 window size 1만큼의 단어\n",
    "# cbow 에서의 output은 현재 i번째 단어\n",
    "# 이를 하기 위해, cbow_pair를 만듬 by using indexed words\n",
    "for i in range(1, len(data)-1):\n",
    "    cbow_pairs.append([[data[i-1], data[i+1]], data[i]]);\n",
    "print(cbow_pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "print(len(cbow_pairs)) # cbow_pair가 몇개있는지 확인해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Skip-gram pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 5], [9, 10], [10, 9], [10, 11], [11, 10]]\n"
     ]
    }
   ],
   "source": [
    "skip_gram_pairs=[]\n",
    "# cp[1]의 의미: [[i-1번째 단어, i+!번째 단어], i번째 단어] 중 i번째 단어를 의미\n",
    "# cp[0][0]의 의미: [[i-1번째 단어, i+!번째 단어], i번째 단어] 중 i-1번째 단어를 의미\n",
    "# cp[0][1]의 의미: [[i-1번째 단어, i+!번째 단어], i번째 단어] 중 i+1번째 단어를 의미\n",
    "# 결국 이것이 하고자 하는 바는,\n",
    "# [i번째 단어, i-1번째 단어], [i번째 단어, i+1번째 단어]를 pair로 만들고 싶다는 의미\n",
    "\n",
    "for cp in cbow_pairs:\n",
    "    skip_gram_pairs.append([cp[1], cp[0][0]])\n",
    "    skip_gram_pairs.append([cp[1], cp[0][1]])\n",
    "    \n",
    "print(skip_gram_pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([4, 0, 1], [[16], [22], [2]])\n"
     ]
    }
   ],
   "source": [
    "def generate_batch(size):\n",
    "    assert size < len(skip_gram_pairs) # batch size가 skip_gram_pair size보다 작으면 진행\n",
    "    x_data=[]\n",
    "    y_data=[]\n",
    "    # random choice의 의미: skip_gram pair중에 random하게 몇번째 skip_gram pair를 쓸지 size만큼 list를 만들어낸다.\n",
    "    # replace=False의 의미: no repeated elements\n",
    "    # 이제 그 list가 r로 만들어졌다면,\n",
    "    # x_data, y_data로 만들어준다.\n",
    "    # Batch를 random하게 sampling한다고 생각하면 된다.\n",
    "    r=np.random.choice(range(len(skip_gram_pairs)), size, replace=False)\n",
    "    for i in r:\n",
    "        x_data.append(skip_gram_pairs[i][0])\n",
    "        y_data.append([skip_gram_pairs[i][1]])\n",
    "    return x_data, y_data\n",
    "\n",
    "print(generate_batch(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training input\n",
    "train_inputs=tf.placeholder(tf.int32, shape=[batch_size])\n",
    "\n",
    "# training output\n",
    "train_output=tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "# Embeddings for inputs\n",
    "# Embedding matrix (Vocabsize X Embedding Size)를 uniform random하게 -1에서 1사이로 initialise 해준다.\n",
    "# Lookup table의 의미: 행렬에 embedding matrix와 training inputs 저장\n",
    "embeddings=tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0))\n",
    "embed=tf.nn.embedding_lookup(embeddings, train_inputs) # Lookup table\n",
    "\n",
    "# Weights Matrix: random uniform (-1,1)사이로 초기화시키기\n",
    "nce_weights=tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0))\n",
    "# Biases vecotr: 0으로 vocabulary size만큼 초기화시키기\n",
    "nce_biases=tf.Variable(tf.zeros([vocab_size]))\n",
    "\n",
    "# Loss 계산 for the Batch\n",
    "# tf.nn.nce_loss의 의미: NCE 손실함수를 사용한다.\n",
    "# NCE = Noise-Contrastive Estimation Loss Function defined for Negative Sampling\n",
    "# NCE의 컨셉의미: 실제 단어에는 높은 확률을 부여하고, 노이즈 단어들에는 낮은 확률을 부여하는 것\n",
    "# tf.nn.nce_loss: loss를 계산할 때마다 negative labels를 가진 새로운 샘플을 자동으로 생성한다.(?)\n",
    "loss=tf.reduce_mean(\n",
    "    tf.nn.nce_loss(weights=nce_weights, biases=nce_biases, inputs=embed, labels=train_output, num_sampled=num_negativeSample, num_classes=vocab_size))\n",
    "\n",
    "# Adam Optimizer\n",
    "# Adam Optimizer의 의미: 빨리 수렴하게 하는 방법 중 하나\n",
    "# Learning rate = 0.01\n",
    "train_op=tf.train.AdamOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run word2Vec!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\udemy\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Loss at the step 0 is 19.01916\n",
      "Loss at the step 100 is 8.13440\n",
      "Loss at the step 200 is 3.90518\n",
      "Loss at the step 300 is 4.01362\n",
      "Loss at the step 400 is 3.53714\n",
      "Loss at the step 500 is 3.28075\n",
      "Loss at the step 600 is 3.35736\n",
      "Loss at the step 700 is 3.08029\n",
      "Loss at the step 800 is 3.45209\n",
      "Loss at the step 900 is 3.17329\n",
      "Loss at the step 1000 is 2.94703\n",
      "Loss at the step 1100 is 3.51902\n",
      "Loss at the step 1200 is 3.28538\n",
      "Loss at the step 1300 is 3.20617\n",
      "Loss at the step 1400 is 2.98876\n",
      "Loss at the step 1500 is 3.21382\n",
      "Loss at the step 1600 is 3.10652\n",
      "Loss at the step 1700 is 3.19409\n",
      "Loss at the step 1800 is 3.10234\n",
      "Loss at the step 1900 is 2.92681\n",
      "Loss at the step 2000 is 3.06823\n",
      "Loss at the step 2100 is 2.94842\n",
      "Loss at the step 2200 is 3.07811\n",
      "Loss at the step 2300 is 3.25209\n",
      "Loss at the step 2400 is 2.80193\n",
      "Loss at the step 2500 is 2.82101\n",
      "Loss at the step 2600 is 3.13590\n",
      "Loss at the step 2700 is 2.92625\n",
      "Loss at the step 2800 is 2.97417\n",
      "Loss at the step 2900 is 2.76616\n",
      "Loss at the step 3000 is 2.90645\n",
      "Loss at the step 3100 is 3.17394\n",
      "Loss at the step 3200 is 3.07014\n",
      "Loss at the step 3300 is 2.81317\n",
      "Loss at the step 3400 is 3.14075\n",
      "Loss at the step 3500 is 3.01571\n",
      "Loss at the step 3600 is 2.94453\n",
      "Loss at the step 3700 is 2.81633\n",
      "Loss at the step 3800 is 2.70610\n",
      "Loss at the step 3900 is 2.79604\n",
      "Loss at the step 4000 is 2.75646\n",
      "Loss at the step 4100 is 2.82772\n",
      "Loss at the step 4200 is 2.98854\n",
      "Loss at the step 4300 is 2.83060\n",
      "Loss at the step 4400 is 2.58567\n",
      "Loss at the step 4500 is 2.55631\n",
      "Loss at the step 4600 is 2.79033\n",
      "Loss at the step 4700 is 2.77067\n",
      "Loss at the step 4800 is 2.59709\n",
      "Loss at the step 4900 is 2.66611\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    \n",
    "    for step in range(5000):\n",
    "        batch_inputs, batch_output = generate_batch(batch_size)\n",
    "        _, loss_val=sess.run([train_op, loss], feed_dict={train_inputs: batch_inputs, train_output: batch_output})\n",
    "        if step % 100 == 0:\n",
    "            print(\"Loss at the step %d is %.5f\" %(step, loss_val))\n",
    "    \n",
    "    # Final Embeddings\n",
    "    # eval()의 의미: 문자열을 실행한 결과값 return\n",
    "    trained_embeddings = embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results\n",
    "\n",
    "Plot Word2vec when embedding size is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.3618722   0.10700534]\n",
      " [-6.38391161  0.4664636 ]\n",
      " [-3.91290402  4.14228678]\n",
      " [-0.15818548  5.30797243]\n",
      " [ 0.01881921  6.0780282 ]\n",
      " [-0.37260032  1.10592616]\n",
      " [-2.14562201  0.34403551]\n",
      " [-0.69799215  1.21435916]\n",
      " [-0.7658056   1.30669761]\n",
      " [ 0.12967163  2.67524672]\n",
      " [-1.12511432  0.34218532]\n",
      " [ 0.27279338  3.78863263]\n",
      " [-0.75296992  0.54229659]\n",
      " [ 0.10826022  2.45220542]\n",
      " [-0.27550861  1.10808837]\n",
      " [-0.02810714  2.31940937]\n",
      " [-2.23359966  0.04854407]\n",
      " [-0.07485858  7.31920624]\n",
      " [-4.27003527  0.01279355]\n",
      " [-0.48502484  5.68641376]\n",
      " [-5.07944536  1.09617853]\n",
      " [-5.77786255  0.40393871]\n",
      " [-2.53349495  0.69428182]\n",
      " [-2.37904477  0.17847686]\n",
      " [-0.32969964  3.56110883]\n",
      " [-0.20349298  2.15235019]\n",
      " [-1.06992054  0.56072778]\n",
      " [-0.36699566  1.25629938]\n",
      " [-0.76630569  0.86080134]\n",
      " [-1.08926606  0.66645718]\n",
      " [-4.84343719  0.54848105]\n",
      " [-2.79810715  0.13097832]\n",
      " [ 0.07285771  4.11188889]\n",
      " [-2.56277752  0.0958671 ]\n",
      " [ 0.04580789  4.98284054]]\n"
     ]
    }
   ],
   "source": [
    "print(trained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbd05de1358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbd06efecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if trained_embeddings.shape[1]==2:\n",
    "    labels=rdic[:20] # 가장 frequent한 top 20 단어들을 뽑아낸다.\n",
    "    for i,label in enumerate(labels):\n",
    "        x,y=trained_embeddings[i,:]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x,y), xytext=(5,2), textcoords='offset points', ha='right', va='bottom')\n",
    "    plt.show()\n",
    "    plt.savefig('Word2Vec.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
